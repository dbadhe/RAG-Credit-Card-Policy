{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "943a1c78",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "Adding all libraries and files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3e4ffeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chromadb\n",
    "import umap.umap_ as umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    SentenceTransformersTokenTextSplitter,\n",
    ")\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "from sentence_transformers import CrossEncoder\n",
    "import ollama\n",
    "import hf_xet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "05a4d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_wrap(s, width=80):\n",
    "    \"\"\"Wraps text to a specified width.\"\"\"\n",
    "    lines = []\n",
    "    for line in s.splitlines():\n",
    "        lines.extend(textwrap.wrap(line, width))\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "def project_embeddings(embeddings, umap_transform):\n",
    "    \"\"\"Projects embeddings using UMAP.\"\"\"\n",
    "    umap_embeddings = np.empty((len(embeddings), 2))\n",
    "    for i, embedding in enumerate(embeddings):\n",
    "        umap_embeddings[i] = umap_transform.transform([embedding])[0]\n",
    "    return umap_embeddings\n",
    "\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af497ec0",
   "metadata": {},
   "source": [
    "## 2. Adding Env variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "caed1f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "#openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "#if not openai_key:\n",
    "#    raise ValueError(\"OPENAI_API_KEY not found in environment variables.\")\n",
    "#client = OpenAI(api_key=openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d79a02dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing Ollama \n",
    "client = ollama.Client()\n",
    "ollama_model = \"gemma3:1b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc99c67",
   "metadata": {},
   "source": [
    "### Processing PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9dde1ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 4 pages from PDF.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    reader = PdfReader(\"Credit_Card_Policy_Doc.pdf\")\n",
    "    pdf_texts = [p.extract_text().strip() for p in reader.pages if p.extract_text()]\n",
    "    raw_text = \"\\n\\n\".join(pdf_texts)\n",
    "    if not raw_text:\n",
    "        raise ValueError(\"No text extracted from PDF.\")\n",
    "    print(f\"Successfully loaded {len(pdf_texts)} pages from PDF.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: PDF file 'Credit_Card_Policy_Doc.pdf' not found.\")\n",
    "    raw_text = \"\" # Set to empty or default if file not found\n",
    "except Exception as e:\n",
    "    print(f\"Error reading PDF: {e}\")\n",
    "    raw_text = \"\" # Set to empty or default on other errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2e0b05",
   "metadata": {},
   "source": [
    "## 3. Splitting text into chunks + embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fa750114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text into chunks\n",
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"], chunk_size=1000, chunk_overlap=0\n",
    ")\n",
    "character_split_texts = character_splitter.split_text(raw_text)\n",
    "\n",
    "token_splitter = SentenceTransformersTokenTextSplitter(\n",
    "    chunk_overlap=0, tokens_per_chunk=256\n",
    ")\n",
    "token_split_texts = []\n",
    "for text in character_split_texts:\n",
    "    token_split_texts.extend(token_splitter.split_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ce57a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total text chunks: 15\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total text chunks: {len(token_split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e8c675a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing collection 'qa-collection' deleted.\n"
     ]
    }
   ],
   "source": [
    "# Setup ChromaDB and Embedding Function\n",
    "embedding_function = SentenceTransformerEmbeddingFunction()\n",
    "chroma_client = chromadb.Client() \n",
    "collection_name = \"qa-collection\"\n",
    "try:\n",
    "    chroma_client.delete_collection(name=collection_name)\n",
    "    print(f\"Existing collection '{collection_name}' deleted.\")\n",
    "except Exception:\n",
    "    pass \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a46fceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding everything together\n",
    "chroma_collection = chroma_client.create_collection(\n",
    "    collection_name, embedding_function=embedding_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e62ed0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 15 documents to ChromaDB.\n"
     ]
    }
   ],
   "source": [
    "# Adding chuunks to ChromaDB\n",
    "if token_split_texts:\n",
    "    ids = [str(i) for i in range(len(token_split_texts))]\n",
    "    chroma_collection.add(ids=ids, documents=token_split_texts)\n",
    "    print(f\"Added {chroma_collection.count()} documents to ChromaDB.\")\n",
    "else:\n",
    "    print(\"Skipping ChromaDB population as no text chunks were generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9caedf1",
   "metadata": {},
   "source": [
    "## 4. Functions for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0c7f9811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(query_texts, n_results=5, collection=chroma_collection):\n",
    "    \"\"\"Retrieves documents from ChromaDB for given queries.\"\"\"\n",
    "    if collection.count() == 0:\n",
    "        print(\"Warning: ChromaDB collection is empty. Cannot retrieve.\")\n",
    "        return {\"ids\": [[] for _ in query_texts], \"documents\": [[] for _ in query_texts], \"embeddings\": [[] for _ in query_texts]}\n",
    "    return collection.query(\n",
    "        query_texts=query_texts, n_results=n_results, include=[\"documents\", \"embeddings\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ffe6f8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_llm_answer(query, context, system_prompt, model=ollama_model): # Use ollama_model as default\n",
    "    \"\"\"Generates an answer using Ollama based on query and context.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"Based on the following context:\\n\\n{context}\\n\\nAnswer the query: '{query}'\"},\n",
    "    ]\n",
    "    try:\n",
    "        # Use the ollama client's chat method\n",
    "        response = client.chat(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "        )\n",
    "        # Extract content from the Ollama response structure\n",
    "        return response['message']['content']\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Ollama: {e}\")\n",
    "        return \"Error generating answer from LLM.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "08f05445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings(\n",
    "    original_query,\n",
    "    projected_dataset_embeddings,\n",
    "    projected_retrieved_embeddings,\n",
    "    projected_original_query_embedding,\n",
    "    projected_augmented_query_embedding=None, # Make augmented optional\n",
    "    filename=\"embeddings_plot.png\"\n",
    "    ):\n",
    "    \"\"\"Plots projected embeddings.\"\"\"\n",
    "    plt.figure()\n",
    "    # [Plotting code as before]...\n",
    "    plt.scatter(\n",
    "        projected_dataset_embeddings[:, 0],\n",
    "        projected_dataset_embeddings[:, 1],\n",
    "        s=10, color=\"gray\", label=\"Dataset Embeddings\"\n",
    "    )\n",
    "    plt.scatter(\n",
    "        projected_retrieved_embeddings[:, 0],\n",
    "        projected_retrieved_embeddings[:, 1],\n",
    "        s=100, facecolors=\"none\", edgecolors=\"g\", label=\"Retrieved Embeddings\"\n",
    "    )\n",
    "    plt.scatter(\n",
    "        projected_original_query_embedding[:, 0],\n",
    "        projected_original_query_embedding[:, 1],\n",
    "        s=150, marker=\"X\", color=\"r\", label=\"Original Query\"\n",
    "    )\n",
    "    if projected_augmented_query_embedding is not None:\n",
    "         plt.scatter(\n",
    "            projected_augmented_query_embedding[:, 0],\n",
    "            projected_augmented_query_embedding[:, 1],\n",
    "            s=150, marker=\"X\", color=\"orange\", label=\"Augmented Query\"\n",
    "        )\n",
    "\n",
    "    plt.gca().set_aspect(\"equal\", \"datalim\")\n",
    "    plt.title(f\"Embeddings for: {word_wrap(original_query)}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.legend()\n",
    "    plt.savefig(filename)\n",
    "    print(f\"Saved embedding plot to {filename}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b572ede3",
   "metadata": {},
   "source": [
    "## 5. Implementing RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "42853d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_query = \"What is the card limit for Associate Vice Presidents?\"\n",
    "customer_service_prompt = \"\"\"\n",
    "You are a knowledgeable customer service agent. You're helpful and very kind as an agent. \n",
    "Customers love talking to you because you answer their questions. \n",
    "Your users are inquiring about credit card policy details. \n",
    "Provide a clear and concise answer based *only* on the provided context. DO NOT reference any other content apart from the document. \n",
    "Provide your answer in an easy to understand format and also cite which page and section you found the information from. \n",
    "\"\"\"\n",
    "n_results_retrieval = 5\n",
    "results_df = pd.DataFrame(columns=[\"Type\", \"Query\", \"Context\", \"Answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e6366988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Strategy: Original Query (No RAG) ---\n",
      "Answer (No RAG): I’m sorry, but the context provided doesn’t contain any information about credit\n",
      "card limits for Associate Vice Presidents.\n",
      "Therefore, I cannot answer your question.\n"
     ]
    }
   ],
   "source": [
    "# --- Strategy 1: Original Query (No RAG) ---\n",
    "print(\"\\n--- Running Strategy: Original Query (No RAG) ---\")\n",
    "answer_no_rag = generate_llm_answer(original_query, \"No context provided.\", customer_service_prompt)\n",
    "results_df.loc[len(results_df)] = [\"Original Query (No RAG)\", original_query, \"N/A\", answer_no_rag]\n",
    "print(\"Answer (No RAG):\", word_wrap(answer_no_rag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f745c84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Strategy: Basic RAG ---\n",
      "Answer (Basic RAG): “The CEO has a limit of up to $10,000.”\n"
     ]
    }
   ],
   "source": [
    "# --- Strategy 2: Basic RAG ---\n",
    "print(\"\\n--- Running Strategy: Basic RAG ---\")\n",
    "retrieved_results_basic = retrieve_documents(query_texts=[original_query], n_results=n_results_retrieval)\n",
    "if retrieved_results_basic[\"documents\"] and retrieved_results_basic[\"documents\"][0]:\n",
    "    context_basic = \"\\n\\n\".join(retrieved_results_basic[\"documents\"][0])\n",
    "    answer_basic_rag = generate_llm_answer(original_query, context_basic, customer_service_prompt)\n",
    "    results_df.loc[len(results_df)] = [\"Basic RAG\", original_query, context_basic, answer_basic_rag]\n",
    "    print(\"Answer (Basic RAG):\", word_wrap(answer_basic_rag))\n",
    "else:\n",
    "    print(\"Skipping Basic RAG answer generation as no documents were retrieved.\")\n",
    "    results_df.loc[len(results_df)] = [\"Basic RAG\", original_query, \"No documents retrieved\", \"N/A\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8e949dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Strategy: Query Expansion (Hypothetical Answer) ---\n",
      "Joint Query: What is the card limit for Associate Vice Presidents? Okay, here’s a helpful and\n",
      "professional response to the query “What is the card limit for Associate Vice\n",
      "Presidents?” keeping in mind a credit card policy context:\n",
      "“Thank you for your inquiry. The card limit for Associate Vice Presidents is\n",
      "generally set at $[Amount - e.g., $10,000] based on factors such as credit\n",
      "history, overall financial responsibility, and card usage patterns.  We want to\n",
      "ensure responsible card usage and maintain the stability of the account.\n",
      "However, this amount is subject to review based on individual circumstances and\n",
      "approval within our policy.  I recommend reviewing the full credit card policy\n",
      "document available on our website at [Link to Policy Document] for a complete\n",
      "understanding of these guidelines.”\n",
      "**Explanation of why this response is good:**\n",
      "* **Acknowledges the Request:**  It starts by thanking the user, which is\n",
      "polite.\n",
      "* **Provides a Range:** It gives a specific, helpful range (e.g., $10,000) -\n",
      "this is crucial.\n",
      "* **Explains the Reason:** It justifies the limit with factors like credit\n",
      "history and responsibility, which are important for a policy.\n",
      "* **Mentions Policy:**  It directs the user to the full policy document – the\n",
      "most important step.\n",
      "* **Professional Tone:** It maintains a courteous and informative tone.\n",
      "**Important Note:** Replace the bracketed placeholder with the *actual* card\n",
      "limit for Associate Vice Presidents as defined by your company’s policy.\n",
      "Answer (Hypothetical Expansion): According to the provided text, the limit for an Associate Vice President’s card\n",
      "is up to $10,000.\n"
     ]
    }
   ],
   "source": [
    "# --- Strategy 3: Query Expansion (Hypothetical Answer) ---\n",
    "print(\"\\n--- Running Strategy: Query Expansion (Hypothetical Answer) ---\")\n",
    "hypothetical_answer_prompt = \"\"\"You are a helpful expert customer support agent.\n",
    "Provide an example answer to the given question, that might be found in a credit card policy documentation.\"\"\"\n",
    "\n",
    "# Using generate_llm_answer for consistency, though the original used a dedicated function\n",
    "hypothetical_answer = generate_llm_answer(original_query, \"\", hypothetical_answer_prompt) # Empty context for generation\n",
    "joint_query_hyp = f\"{original_query} {hypothetical_answer}\"\n",
    "print(\"Joint Query:\", word_wrap(joint_query_hyp))\n",
    "\n",
    "retrieved_results_hyp = retrieve_documents(query_texts=[joint_query_hyp], n_results=n_results_retrieval)\n",
    "if retrieved_results_hyp[\"documents\"] and retrieved_results_hyp[\"documents\"][0]:\n",
    "    context_hyp = \"\\n\\n\".join(retrieved_results_hyp[\"documents\"][0])\n",
    "    answer_hyp_rag = generate_llm_answer(original_query, context_hyp, customer_service_prompt) # Use original query for final answer\n",
    "    results_df.loc[len(results_df)] = [\"Query Expansion (Hypothetical)\", joint_query_hyp, context_hyp, answer_hyp_rag]\n",
    "    print(\"Answer (Hypothetical Expansion):\", word_wrap(answer_hyp_rag))\n",
    "else:\n",
    "    print(\"Skipping Hypothetical Expansion answer generation as no documents were retrieved.\")\n",
    "    results_df.loc[len(results_df)] = [\"Query Expansion (Hypothetical)\", joint_query_hyp, \"No documents retrieved\", \"N/A\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4a8977b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Strategy: Query Expansion (Multiple Subqueries) ---\n",
      "Generated Subqueries: ['*   What is the maximum dollar amount the card allows for this role?', '*   Are there any restrictions on spending limits associated with this card?', '*   Does the card offer any spending thresholds that trigger a higher limit?', '*   Can you clarify if the card limit is consistent across all departments or roles?', '*   Is there a specific amount exceeding which the card limit would be impacted?']\n",
      "Answer (Subquery Expansion): “The card limit for an Associate Vice President is up to $10,000.”\n"
     ]
    }
   ],
   "source": [
    "# --- Strategy 4: Query Expansion (Multiple Subqueries) ---\n",
    "print(\"\\n--- Running Strategy: Query Expansion (Multiple Subqueries) ---\")\n",
    "subquery_gen_prompt = \"\"\"\n",
    "You are a knowledgeable customer service agent.\n",
    "Your users are inquiring about credit card policy details.\n",
    "For the given question, propose up to five *distinct* and *related* questions to help find the information needed.\n",
    "Provide concise, single-topic questions. Each question should be complete and directly related to the original inquiry.\n",
    "List each question on a separate line without numbering.\n",
    "\"\"\"\n",
    "# Using generate_llm_answer again\n",
    "subqueries_str = generate_llm_answer(original_query, \"\", subquery_gen_prompt)\n",
    "subqueries = [q.strip() for q in subqueries_str.split(\"\\n\") if q.strip() and not q.strip().startswith(\"1.\")] # Basic cleaning\n",
    "\n",
    "print(\"Generated Subqueries:\", subqueries)\n",
    "all_queries_sub = [original_query] + subqueries\n",
    "retrieved_results_sub = retrieve_documents(query_texts=all_queries_sub, n_results=n_results_retrieval)\n",
    "\n",
    "# Deduplicate documents\n",
    "unique_docs_sub = set()\n",
    "if retrieved_results_sub[\"documents\"]:\n",
    "    for doc_list in retrieved_results_sub[\"documents\"]:\n",
    "        unique_docs_sub.update(doc_list)\n",
    "context_sub = \"\\n\\n\".join(list(unique_docs_sub))\n",
    "\n",
    "if context_sub:\n",
    "    answer_sub_rag = generate_llm_answer(original_query, context_sub, customer_service_prompt) # Use original query\n",
    "    results_df.loc[len(results_df)] = [\"Query Expansion (Subqueries)\", \" | \".join(all_queries_sub), context_sub, answer_sub_rag]\n",
    "    print(\"Answer (Subquery Expansion):\", word_wrap(answer_sub_rag))\n",
    "else:\n",
    "    print(\"Skipping Subquery Expansion answer generation as no documents were retrieved.\")\n",
    "    results_df.loc[len(results_df)] = [\"Query Expansion (Subqueries)\", \" | \".join(all_queries_sub), \"No documents retrieved\", \"N/A\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b8eb5a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Strategy: Re-ranking ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-ranking initial retrieved documents...\n",
      "Answer (Re-ranking Initial): The card limit for Associate Vice Presidents is up to $10,000.\n"
     ]
    }
   ],
   "source": [
    "# --- Strategy 5: Re-ranking with CrossEncoder ---\n",
    "print(\"\\n--- Running Strategy: Re-ranking ---\")\n",
    "cross_encoder = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "# Option 1: Re-rank initial results (from Basic RAG)\n",
    "print(\"Re-ranking initial retrieved documents...\")\n",
    "if retrieved_results_basic[\"documents\"] and retrieved_results_basic[\"documents\"][0]:\n",
    "    initial_docs = retrieved_results_basic[\"documents\"][0]\n",
    "    pairs_rerank_initial = [[original_query, doc] for doc in initial_docs]\n",
    "    scores_initial = cross_encoder.predict(pairs_rerank_initial)\n",
    "    reranked_indices_initial = np.argsort(scores_initial)[::-1]\n",
    "    context_reranked_initial = \"\\n\\n\".join([initial_docs[i] for i in reranked_indices_initial])\n",
    "    answer_reranked_initial = generate_llm_answer(original_query, context_reranked_initial, customer_service_prompt)\n",
    "    results_df.loc[len(results_df)] = [\"Re-ranking (Initial)\", original_query, context_reranked_initial, answer_reranked_initial]\n",
    "    print(\"Answer (Re-ranking Initial):\", word_wrap(answer_reranked_initial))\n",
    "else:\n",
    "     print(\"Skipping Initial Re-ranking as no documents were retrieved initially.\")\n",
    "     results_df.loc[len(results_df)] = [\"Re-ranking (Initial)\", original_query, \"No documents retrieved\", \"N/A\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e7cea997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Re-ranking documents retrieved via subqueries...\n",
      "Answer (Re-ranking Subqueries): According to the provided text, the card limit for Associate Vice Presidents is\n",
      "“approved by an associate vice president or vice president.”\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Re-rank deduplicated results from subqueries\n",
    "print(\"\\nRe-ranking documents retrieved via subqueries...\")\n",
    "if unique_docs_sub:\n",
    "    pairs_rerank_sub = [[original_query, doc] for doc in unique_docs_sub]\n",
    "    scores_sub = cross_encoder.predict(pairs_rerank_sub)\n",
    "    # Select top N unique documents based on score\n",
    "    top_n_rerank = 5 # Or keep original number retrieved per query\n",
    "    reranked_indices_sub = np.argsort(scores_sub)[::-1][:top_n_rerank]\n",
    "    context_reranked_sub = \"\\n\\n\".join([list(unique_docs_sub)[i] for i in reranked_indices_sub])\n",
    "    answer_reranked_sub = generate_llm_answer(original_query, context_reranked_sub, customer_service_prompt)\n",
    "    results_df.loc[len(results_df)] = [\"Re-ranking (Subqueries)\", \" | \".join(all_queries_sub), context_reranked_sub, answer_reranked_sub]\n",
    "    print(\"Answer (Re-ranking Subqueries):\", word_wrap(answer_reranked_sub))\n",
    "else:\n",
    "     print(\"Skipping Subquery Re-ranking as no documents were retrieved via subqueries.\")\n",
    "     results_df.loc[len(results_df)] = [\"Re-ranking (Subqueries)\", \" | \".join(all_queries_sub), \"No documents retrieved\", \"N/A\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bd89f4",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16150f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Comparison ---\n",
      "                             Type                                                                                                                                                                     Answer\n",
      "0         Original Query (No RAG)  I’m sorry, but the context provided doesn’t contain any information about credit card limits for Associate Vice Presidents. \\n\\nTherefore, I cannot answer your question.\n",
      "1                       Basic RAG                                                                                                                                    “The CEO has a limit of up to $10,000.”\n",
      "2  Query Expansion (Hypothetical)                                                                         According to the provided text, the limit for an Associate Vice President’s card is up to $10,000.\n",
      "3    Query Expansion (Subqueries)                                                                                                         “The card limit for an Associate Vice President is up to $10,000.”\n",
      "4            Re-ranking (Initial)                                                                                                             The card limit for Associate Vice Presidents is up to $10,000.\n",
      "5         Re-ranking (Subqueries)                               According to the provided text, the card limit for Associate Vice Presidents is “approved by an associate vice president or vice president.”\n",
      "\n",
      "Saved final comparison to results_comparison.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Query</th>\n",
       "      <th>Context</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Original Query (No RAG)</td>\n",
       "      <td>What is the card limit for Associate Vice Pres...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>I’m sorry, but the context provided doesn’t co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Basic RAG</td>\n",
       "      <td>What is the card limit for Associate Vice Pres...</td>\n",
       "      <td>which accrue through use of the credit card wi...</td>\n",
       "      <td>“The CEO has a limit of up to $10,000.”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Query Expansion (Hypothetical)</td>\n",
       "      <td>What is the card limit for Associate Vice Pres...</td>\n",
       "      <td>which accrue through use of the credit card wi...</td>\n",
       "      <td>According to the provided text, the limit for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Query Expansion (Subqueries)</td>\n",
       "      <td>What is the card limit for Associate Vice Pres...</td>\n",
       "      <td>eligibility ( authorized employees ) employees...</td>\n",
       "      <td>“The card limit for an Associate Vice Presiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Re-ranking (Initial)</td>\n",
       "      <td>What is the card limit for Associate Vice Pres...</td>\n",
       "      <td>• once the authorization form is received, a r...</td>\n",
       "      <td>The card limit for Associate Vice Presidents i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Re-ranking (Subqueries)</td>\n",
       "      <td>What is the card limit for Associate Vice Pres...</td>\n",
       "      <td>1 corporate credit card policy policy # 7. 36 ...</td>\n",
       "      <td>According to the provided text, the card limit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Type  \\\n",
       "0         Original Query (No RAG)   \n",
       "1                       Basic RAG   \n",
       "2  Query Expansion (Hypothetical)   \n",
       "3    Query Expansion (Subqueries)   \n",
       "4            Re-ranking (Initial)   \n",
       "5         Re-ranking (Subqueries)   \n",
       "\n",
       "                                               Query  \\\n",
       "0  What is the card limit for Associate Vice Pres...   \n",
       "1  What is the card limit for Associate Vice Pres...   \n",
       "2  What is the card limit for Associate Vice Pres...   \n",
       "3  What is the card limit for Associate Vice Pres...   \n",
       "4  What is the card limit for Associate Vice Pres...   \n",
       "5  What is the card limit for Associate Vice Pres...   \n",
       "\n",
       "                                             Context  \\\n",
       "0                                                N/A   \n",
       "1  which accrue through use of the credit card wi...   \n",
       "2  which accrue through use of the credit card wi...   \n",
       "3  eligibility ( authorized employees ) employees...   \n",
       "4  • once the authorization form is received, a r...   \n",
       "5  1 corporate credit card policy policy # 7. 36 ...   \n",
       "\n",
       "                                              Answer  \n",
       "0  I’m sorry, but the context provided doesn’t co...  \n",
       "1            “The CEO has a limit of up to $10,000.”  \n",
       "2  According to the provided text, the limit for ...  \n",
       "3  “The card limit for an Associate Vice Presiden...  \n",
       "4  The card limit for Associate Vice Presidents i...  \n",
       "5  According to the provided text, the card limit...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results_df = results_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"\\n--- Final Comparison ---\")\n",
    "print(results_df[['Type', 'Answer']].to_string()) # Display Type and Answer clearly\n",
    "\n",
    "\n",
    "results_df.to_csv('results_comparison.csv', index=False)\n",
    "print(\"\\nSaved final comparison to results_comparison.csv\")\n",
    "\n",
    "\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
